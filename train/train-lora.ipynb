{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDJUrFOrYEfL",
    "outputId": "0a6c954f-1d15-479a-e068-f26319d422e0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: accelerate in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (0.29.1)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.44.1-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from wandb) (69.1.1)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: transformers in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from peft) (4.39.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from transformers->peft) (0.15.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.44.1-py2.py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, gitdb, GitPython, wandb, peft\n",
      "Successfully installed GitPython-3.1.43 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 peft-0.10.0 protobuf-4.25.3 sentry-sdk-1.44.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets accelerate wandb peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaQ5t8UY1BlX",
    "outputId": "209065ba-7736-4121-8d1a-7de691e165cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/factory/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wandb import login\n",
    "\n",
    "login(\"never\", \"***REMOVED***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPi2ZNoFh9xN",
    "outputId": "8262ae94-bc06-4616-b2cc-fbab0c116e76",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/factory/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token ***REMOVED***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfG_fx-ShLR8",
    "outputId": "9c1b8315-1615-421b-8265-2bc551e9450a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/factory/work/mb/factory/train/diffusers\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: importlib-metadata in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (7.1.0)\n",
      "Requirement already satisfied: filelock in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (0.22.2)\n",
      "Requirement already satisfied: numpy in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: Pillow in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (10.3.0)\n",
      "Requirement already satisfied: torch>=1.4 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: accelerate>=0.11.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from diffusers==0.28.0.dev0) (0.29.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from accelerate>=0.11.0->diffusers==0.28.0.dev0) (24.0)\n",
      "Requirement already satisfied: psutil in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from accelerate>=0.11.0->diffusers==0.28.0.dev0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from accelerate>=0.11.0->diffusers==0.28.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from torch>=1.4->diffusers==0.28.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->diffusers==0.28.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from importlib-metadata->diffusers==0.28.0.dev0) (3.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests->diffusers==0.28.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests->diffusers==0.28.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests->diffusers==0.28.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from requests->diffusers==0.28.0.dev0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from jinja2->torch>=1.4->diffusers==0.28.0.dev0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages (from sympy->torch>=1.4->diffusers==0.28.0.dev0) (1.3.0)\n",
      "Checking if build backend supports build_editable: started\n",
      "Checking if build backend supports build_editable: finished with status 'done'\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building editable for diffusers (pyproject.toml): started\n",
      "  Building editable for diffusers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for diffusers: filename=diffusers-0.28.0.dev0-0.editable-py3-none-any.whl size=11125 sha256=3631fb8ef6e09df895068cf5a38030489d8ce20bb396387d3006ad890dc1b2da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o39jjv8o/wheels/d1/b6/6a/a069c5e6ecc9b8613a21fa5cbd448bb596f3571e61beba33d5\n",
      "Successfully built diffusers\n",
      "Installing collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.27.2\n",
      "    Uninstalling diffusers-0.27.2:\n",
      "      Successfully uninstalled diffusers-0.27.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "factory 0.0.0a0 requires diffusers<0.28.0,>=0.27.2, but you have diffusers 0.28.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed diffusers-0.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "git clone https://github.com/huggingface/diffusers.git\n",
    "cd diffusers\n",
    "pip install -e \".[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvHiknuIg3pp",
    "outputId": "b5620a9a-d705-449e-e4be-b92d01f08bcb"
   },
   "outputs": [],
   "source": [
    "!scp diffusers/examples/dreambooth/train_dreambooth_lora.py train_dreambooth_lora.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKulUFd8fS_T",
    "outputId": "ca869967-2146-43b7-fba0-f2d55294c41d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "04/07/2024 14:13:47 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'cross_attention_norm', 'time_embedding_type', 'use_linear_projection', 'only_cross_attention', 'addition_time_embed_dim', 'num_class_embeds', 'transformer_layers_per_block', 'num_attention_heads', 'addition_embed_type_num_heads', 'timestep_post_act', 'attention_type', 'time_embedding_act_fn', 'encoder_hid_dim', 'dropout', 'dual_cross_attention', 'resnet_out_scale_factor', 'mid_block_scale_factor', 'encoder_hid_dim_type', 'resnet_skip_time_act', 'time_embedding_dim', 'conv_out_kernel', 'mid_block_only_cross_attention', 'addition_embed_type', 'class_embed_type', 'class_embeddings_concat', 'projection_class_embeddings_input_dim', 'upcast_attention', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'conv_in_kernel', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphilipp-zettl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/factory/work/mb/factory/train/wandb/run-20240407_141351-3a2i706s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjolly-moon-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/philipp-zettl/dreambooth-lora\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/philipp-zettl/dreambooth-lora/runs/3a2i706s\u001b[0m\n",
      "04/07/2024 14:13:51 - INFO - __main__ - ***** Running training *****\n",
      "04/07/2024 14:13:51 - INFO - __main__ -   Num examples = 11\n",
      "04/07/2024 14:13:51 - INFO - __main__ -   Num batches each epoch = 11\n",
      "04/07/2024 14:13:51 - INFO - __main__ -   Num Epochs = 46\n",
      "04/07/2024 14:13:52 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "04/07/2024 14:13:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "04/07/2024 14:13:52 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "04/07/2024 14:13:52 - INFO - __main__ -   Total optimization steps = 500\n",
      "Steps:   2%|▏          | 11/500 [00:13<09:32,  1.17s/it, loss=0.614, lr=9.99e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  9.30it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  60%|███████▊     | 3/5 [00:00<00:00,  7.62it/s]\u001b[A{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 13.09it/s]\n",
      "04/07/2024 14:14:06 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  13%|█▍         | 66/500 [01:43<08:17,  1.15s/it, loss=0.175, lr=9.58e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  9.03it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 18.37it/s]\n",
      "04/07/2024 14:15:35 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  20%|██        | 100/500 [02:46<08:26,  1.27s/it, loss=0.485, lr=9.06e-5]04/07/2024 14:16:38 - INFO - accelerate.accelerator - Saving current state to ./models/margot_robbie-full-lora/checkpoint-100\n",
      "Model weights saved in models/margot_robbie-full-lora/checkpoint-100/pytorch_lora_weights.safetensors\n",
      "04/07/2024 14:16:38 - INFO - accelerate.checkpointing - Optimizer state saved in models/margot_robbie-full-lora/checkpoint-100/optimizer.bin\n",
      "04/07/2024 14:16:38 - INFO - accelerate.checkpointing - Scheduler state saved in models/margot_robbie-full-lora/checkpoint-100/scheduler.bin\n",
      "04/07/2024 14:16:38 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in models/margot_robbie-full-lora/checkpoint-100/sampler.bin\n",
      "04/07/2024 14:16:38 - INFO - accelerate.checkpointing - Random states saved in models/margot_robbie-full-lora/checkpoint-100/random_states_0.pkl\n",
      "04/07/2024 14:16:38 - INFO - __main__ - Saved state to ./models/margot_robbie-full-lora/checkpoint-100\n",
      "Steps:  24%|██▍       | 121/500 [03:11<07:13,  1.14s/it, loss=0.287, lr=8.62e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  8.92it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 18.25it/s]\n",
      "04/07/2024 14:17:04 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  35%|███▏     | 176/500 [04:39<06:23,  1.18s/it, loss=0.0598, lr=7.24e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  9.95it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 19.87it/s]\n",
      "04/07/2024 14:18:31 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  40%|███▌     | 200/500 [05:29<05:53,  1.18s/it, loss=0.0467, lr=6.57e-5]04/07/2024 14:19:21 - INFO - accelerate.accelerator - Saving current state to ./models/margot_robbie-full-lora/checkpoint-200\n",
      "Model weights saved in models/margot_robbie-full-lora/checkpoint-200/pytorch_lora_weights.safetensors\n",
      "04/07/2024 14:19:21 - INFO - accelerate.checkpointing - Optimizer state saved in models/margot_robbie-full-lora/checkpoint-200/optimizer.bin\n",
      "04/07/2024 14:19:21 - INFO - accelerate.checkpointing - Scheduler state saved in models/margot_robbie-full-lora/checkpoint-200/scheduler.bin\n",
      "04/07/2024 14:19:21 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in models/margot_robbie-full-lora/checkpoint-200/sampler.bin\n",
      "04/07/2024 14:19:22 - INFO - accelerate.checkpointing - Random states saved in models/margot_robbie-full-lora/checkpoint-200/random_states_0.pkl\n",
      "04/07/2024 14:19:22 - INFO - __main__ - Saved state to ./models/margot_robbie-full-lora/checkpoint-200\n",
      "Steps:  46%|█████      | 231/500 [06:07<05:13,  1.17s/it, loss=0.124, lr=5.6e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00, 10.28it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 20.36it/s]\n",
      "04/07/2024 14:20:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  57%|████▌   | 286/500 [07:39<04:24,  1.24s/it, loss=0.00868, lr=3.88e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  9.10it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 18.58it/s]\n",
      "04/07/2024 14:21:32 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  60%|██████▌    | 300/500 [08:20<04:30,  1.35s/it, loss=0.34, lr=3.48e-5]04/07/2024 14:22:13 - INFO - accelerate.accelerator - Saving current state to ./models/margot_robbie-full-lora/checkpoint-300\n",
      "Model weights saved in models/margot_robbie-full-lora/checkpoint-300/pytorch_lora_weights.safetensors\n",
      "04/07/2024 14:22:13 - INFO - accelerate.checkpointing - Optimizer state saved in models/margot_robbie-full-lora/checkpoint-300/optimizer.bin\n",
      "04/07/2024 14:22:13 - INFO - accelerate.checkpointing - Scheduler state saved in models/margot_robbie-full-lora/checkpoint-300/scheduler.bin\n",
      "04/07/2024 14:22:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in models/margot_robbie-full-lora/checkpoint-300/sampler.bin\n",
      "04/07/2024 14:22:13 - INFO - accelerate.checkpointing - Random states saved in models/margot_robbie-full-lora/checkpoint-300/random_states_0.pkl\n",
      "04/07/2024 14:22:13 - INFO - __main__ - Saved state to ./models/margot_robbie-full-lora/checkpoint-300\n",
      "Steps:  68%|██████▊   | 341/500 [09:12<03:14,  1.22s/it, loss=0.448, lr=2.29e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  9.07it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 18.08it/s]\n",
      "04/07/2024 14:23:05 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  79%|███████▉  | 396/500 [10:45<02:05,  1.21s/it, loss=0.782, lr=1.03e-5]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  8.61it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 17.61it/s]\n",
      "04/07/2024 14:24:38 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  80%|████████  | 400/500 [11:13<06:04,  3.65s/it, loss=0.355, lr=9.73e-6]04/07/2024 14:25:05 - INFO - accelerate.accelerator - Saving current state to ./models/margot_robbie-full-lora/checkpoint-400\n",
      "Model weights saved in models/margot_robbie-full-lora/checkpoint-400/pytorch_lora_weights.safetensors\n",
      "04/07/2024 14:25:06 - INFO - accelerate.checkpointing - Optimizer state saved in models/margot_robbie-full-lora/checkpoint-400/optimizer.bin\n",
      "04/07/2024 14:25:06 - INFO - accelerate.checkpointing - Scheduler state saved in models/margot_robbie-full-lora/checkpoint-400/scheduler.bin\n",
      "04/07/2024 14:25:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in models/margot_robbie-full-lora/checkpoint-400/sampler.bin\n",
      "04/07/2024 14:25:06 - INFO - accelerate.checkpointing - Random states saved in models/margot_robbie-full-lora/checkpoint-400/random_states_0.pkl\n",
      "04/07/2024 14:25:06 - INFO - __main__ - Saved state to ./models/margot_robbie-full-lora/checkpoint-400\n",
      "Steps:  90%|█████████ | 451/500 [12:18<00:59,  1.21s/it, loss=0.189, lr=2.35e-6]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  6.04it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 13.16it/s]\n",
      "04/07/2024 14:26:11 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Steps: 100%|████████| 500/500 [13:42<00:00,  1.24s/it, loss=0.0445, lr=9.87e-10]04/07/2024 14:27:34 - INFO - accelerate.accelerator - Saving current state to ./models/margot_robbie-full-lora/checkpoint-500\n",
      "Model weights saved in models/margot_robbie-full-lora/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "04/07/2024 14:27:35 - INFO - accelerate.checkpointing - Optimizer state saved in models/margot_robbie-full-lora/checkpoint-500/optimizer.bin\n",
      "04/07/2024 14:27:35 - INFO - accelerate.checkpointing - Scheduler state saved in models/margot_robbie-full-lora/checkpoint-500/scheduler.bin\n",
      "04/07/2024 14:27:35 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in models/margot_robbie-full-lora/checkpoint-500/sampler.bin\n",
      "04/07/2024 14:27:35 - INFO - accelerate.checkpointing - Random states saved in models/margot_robbie-full-lora/checkpoint-500/random_states_0.pkl\n",
      "04/07/2024 14:27:35 - INFO - __main__ - Saved state to ./models/margot_robbie-full-lora/checkpoint-500\n",
      "Steps: 100%|████████████████| 500/500 [13:43<00:00,  1.24s/it, loss=0.254, lr=0]vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00, 10.17it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00, 20.02it/s]\n",
      "04/07/2024 14:27:36 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Model weights saved in models/margot_robbie-full-lora/pytorch_lora_weights.safetensors\n",
      "unet/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.39it/s]\u001b[A{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  3.92it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "{'cross_attention_norm', 'time_embedding_type', 'use_linear_projection', 'only_cross_attention', 'addition_time_embed_dim', 'num_class_embeds', 'transformer_layers_per_block', 'num_attention_heads', 'addition_embed_type_num_heads', 'timestep_post_act', 'attention_type', 'time_embedding_act_fn', 'encoder_hid_dim', 'dropout', 'dual_cross_attention', 'resnet_out_scale_factor', 'mid_block_scale_factor', 'encoder_hid_dim_type', 'resnet_skip_time_act', 'time_embedding_dim', 'conv_out_kernel', 'mid_block_only_cross_attention', 'addition_embed_type', 'class_embed_type', 'class_embeddings_concat', 'projection_class_embeddings_input_dim', 'upcast_attention', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'conv_in_kernel', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
      "Loaded unet as UNet2DConditionModel from `unet` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  80%|██████████▍  | 4/5 [00:01<00:00,  3.05it/s]\u001b[A{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:01<00:00,  3.95it/s]\n",
      "Loading unet.\n",
      "04/07/2024 14:28:00 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: MAGROB style woman on a field of flowers.\n",
      "{'final_sigmas_type', 'use_lu_lambdas', 'euler_at_final', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/work/mb/factory/train/train_dreambooth_lora.py\", line 1429, in <module>\n",
      "    main(args)\n",
      "  File \"/home/factory/work/mb/factory/train/train_dreambooth_lora.py\", line 1398, in main\n",
      "    images = log_validation(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/train_dreambooth_lora.py\", line 154, in log_validation\n",
      "    image = pipeline(**pipeline_args, generator=generator).images[0]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 1013, in __call__\n",
      "    image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False, generator=generator)[\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/models/autoencoders/autoencoder_kl.py\", line 304, in decode\n",
      "    decoded = self._decode(z).sample\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/models/autoencoders/autoencoder_kl.py\", line 275, in _decode\n",
      "    dec = self.decoder(z)\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/models/autoencoders/vae.py\", line 338, in forward\n",
      "    sample = up_block(sample, latent_embeds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/models/unets/unet_2d_blocks.py\", line 2737, in forward\n",
      "    hidden_states = resnet(hidden_states, temb=temb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/work/mb/factory/train/diffusers/src/diffusers/models/resnet.py\", line 327, in forward\n",
      "    hidden_states = self.norm1(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 287, in forward\n",
      "    return F.group_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/functional.py\", line 2561, in group_norm\n",
      "    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 5.78 GiB of which 246.88 MiB is free. Including non-PyTorch memory, this process has 5.21 GiB memory in use. Of the allocated memory 4.67 GiB is allocated by PyTorch, and 412.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Steps: 100%|████████████████| 500/500 [14:14<00:00,  1.71s/it, loss=0.254, lr=0]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1075, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 681, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/bin/python', 'train_dreambooth_lora.py', '--pretrained_model_name_or_path=segmind/tiny-sd', '--instance_data_dir=./datasets/margot_robbie', '--output_dir=./models/margot_robbie-full-lora', '--instance_prompt=MAGROB style', '--class_data_dir=./datasets/image_data', '--class_prompt=style', '--with_prior_preservation', '--num_class_images=10', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--checkpointing_steps=100', '--learning_rate=1e-4', '--report_to=wandb', '--lr_scheduler=cosine_with_restarts', '--lr_warmup_steps=0', '--max_train_steps=500', '--validation_prompt=MAGROB style woman on a field of flowers', '--validation_epochs=5', '--seed=0', '--push_to_hub', '--hub_model_id', 'philipp-zettl/margot_robbie-lora']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path='segmind/tiny-sd'  \\\n",
    "  --instance_data_dir='./datasets/margot_robbie' \\\n",
    "  --output_dir='./models/margot_robbie-full-lora' \\\n",
    "  --instance_prompt=\"MAGROB style\" \\\n",
    "  --class_data_dir='./datasets/image_data' \\\n",
    "  --class_prompt='style' \\\n",
    "  --with_prior_preservation \\\n",
    "  --num_class_images=10 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --checkpointing_steps=100 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=500 \\\n",
    "  --validation_prompt=\"MAGROB style woman on a field of flowers\" \\\n",
    "  --validation_epochs=5 \\\n",
    "  --seed=\"0\" \\\n",
    "  --push_to_hub \\\n",
    "  --hub_model_id \"philipp-zettl/margot_robbie-lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IgQRvZniF3o"
   },
   "outputs": [],
   "source": [
    "!rm -rf train_lora.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_dreambooth_lora import *\n",
    "\n",
    "pretrained_model_name_or_path = 'segmind/tiny-sd'\n",
    "revision = None\n",
    "variant = None\n",
    "weight_dtype = torch.float16\n",
    "output_dir = './models/margot_robbie-full-lora/'\n",
    "logging_dir = 'logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_validation(\n",
    "    pipeline,\n",
    "    args,\n",
    "    accelerator,\n",
    "    pipeline_args,\n",
    "    epoch,\n",
    "    is_final_validation=False,\n",
    "):\n",
    "    logger.info(\n",
    "        f\"Running validation... \\n Generating {args.num_validation_images} images with prompt:\"\n",
    "        f\" {args.validation_prompt}.\"\n",
    "    )\n",
    "    # We train on the simplified learning objective. If we were previously predicting a variance, we need the scheduler to ignore it\n",
    "    scheduler_args = {}\n",
    "\n",
    "    if \"variance_type\" in pipeline.scheduler.config:\n",
    "        variance_type = pipeline.scheduler.config.variance_type\n",
    "\n",
    "        if variance_type in [\"learned\", \"learned_range\"]:\n",
    "            variance_type = \"fixed_small\"\n",
    "\n",
    "        scheduler_args[\"variance_type\"] = variance_type\n",
    "\n",
    "    pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
    "\n",
    "    pipeline = pipeline.to(accelerator.device)\n",
    "    pipeline.set_progress_bar_config(disable=True)\n",
    "\n",
    "    # run inference\n",
    "    generator = torch.Generator(device=accelerator.device).manual_seed(args.seed) if args.seed else None\n",
    "\n",
    "    images = []\n",
    "    for _ in range(args.num_validation_images):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image = pipeline(**pipeline_args, generator=generator).images[0]\n",
    "            images.append(image)\n",
    "\n",
    "    for tracker in accelerator.trackers:\n",
    "        phase_name = \"test\" if is_final_validation else \"validation\"\n",
    "        if tracker.name == \"tensorboard\":\n",
    "            np_images = np.stack([np.asarray(img) for img in images])\n",
    "            tracker.writer.add_images(phase_name, np_images, epoch, dataformats=\"NHWC\")\n",
    "        if tracker.name == \"wandb\":\n",
    "            tracker.log(\n",
    "                {\n",
    "                    phase_name: [\n",
    "                        wandb.Image(image, caption=f\"{i}: {args.validation_prompt}\") for i, image in enumerate(images)\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "    del pipeline\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooArgs:\n",
    "    num_validation_images = 10\n",
    "    seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb776d9b1284891860e198b56fe7961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    pretrained_model_name_or_path, revision=revision, variant=variant, torch_dtype=weight_dtype\n",
    ")\n",
    "\n",
    "# load attention processors\n",
    "pipeline.load_lora_weights(output_dir, weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "\n",
    "logging_dir = Path(output_dir, logging_dir)\n",
    "accelerator_project_config = ProjectConfiguration(project_dir=output_dir, logging_dir=logging_dir)\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=1,\n",
    "    mixed_precision='fp16',\n",
    "    log_with='wandb',\n",
    "    project_config=accelerator_project_config,\n",
    ")\n",
    "# run inference\n",
    "images = []\n",
    "validation_prompt = 'MAGROB style a woman in a field'\n",
    "\n",
    "if validation_prompt:\n",
    "    pipeline_args = {\"prompt\": validation_prompt, \"num_inference_steps\": 25}\n",
    "    images = log_validation(\n",
    "        pipeline,\n",
    "        FooArgs(),\n",
    "        accelerator,\n",
    "        pipeline_args,\n",
    "        500,\n",
    "        is_final_validation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae/diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb50dd6f3334db5ad7958c4d199895d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3046678f934b1aa20a06af00899d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.bin:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e181313391654ddb9bd7b2899e1e6a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 21 LFS files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466b01706f604ad4bf78ed3918cf481b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "random_states_0.pkl:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dac151b1884c1f96e0267d54ac6b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.bin:   0%|          | 0.00/3.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8154b4138b924335a67fe29bfdb80c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.bin:   0%|          | 0.00/3.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73b025f59274ee0b5655d74b203dcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49445b87621948fda90b075dfbb604ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10927ff05ea3415ebe20ea8d4b6af035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "random_states_0.pkl:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242070e75da1440fae057d4b39c64429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.bin:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb398a55ba246a6939bd2686e86d8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999c3bd0ef5a4b3fbe1157b7247c38c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.bin:   0%|          | 0.00/3.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b864da0fc8c04f0c95ede8a1415f4714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "random_states_0.pkl:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321d652276174ca09da1979a7d191a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.bin:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6965e895324a9e85def9d7211f1a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.bin:   0%|          | 0.00/3.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e86e6771b14b7bb5d5842763b849c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616717f3d35043bc8dfa94dff6fa25cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "random_states_0.pkl:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b48923eb3864ae8853ca2a92b6d451e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.bin:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f48594de8f34fcb80d7f9cb642186b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.bin:   0%|          | 0.00/3.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6c35325e8b48c38f4fbb9be49bdec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6eb474c54374c6c8897ac3f5e3189f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "random_states_0.pkl:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df117721dfd94380bc3a194b06d5259b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.bin:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da36e5cb4ef14efaab02d1b74ad7115b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/philipp-zettl/margot_robbie-lora/commit/9763b6bc9d090b59e81b579aea7a414eab1ed3c1', commit_message='End of training', commit_description='', oid='9763b6bc9d090b59e81b579aea7a414eab1ed3c1', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    'segmind/tiny-sd',\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    revision=None\n",
    ")\n",
    "save_model_card(\n",
    "    \"philipp-zettl/margot_robbie-lora\",\n",
    "    images=images,\n",
    "    base_model='segmind/tiny-sd',\n",
    "    train_text_encoder=False,\n",
    "    prompt=\"MAGROB style\",\n",
    "    repo_folder='./models/margot_robbie-full-lora/',\n",
    "    pipeline=pipeline,\n",
    ")\n",
    "upload_folder(\n",
    "    repo_id='philipp-zettl/margot_robbie-lora',\n",
    "    folder_path='./models/margot_robbie-full-lora/',\n",
    "    commit_message=\"End of training\",\n",
    "    ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py ./train_text_to_image_lora_sdxl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/accelerator.py:391: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "04/07/2024 16:39:25 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/segmind/tiny-sd/resolve/main/tokenizer_2/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/transformers/utils/hub.py\", line 398, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 119, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1261, in hf_hub_download\n",
      "    metadata = get_hf_file_metadata(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 119, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1674, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 369, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 393, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 315, in hf_raise_for_status\n",
      "    raise EntryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-6612b01d-62e2acf376a0693e376b1466;a86555af-6187-432f-9f43-19d9e49afe77)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/segmind/tiny-sd/resolve/main/tokenizer_2/config.json.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/work/mb/factory/train/train_text_to_image_lora_sdxl.py\", line 1328, in <module>\n",
      "    main(args)\n",
      "  File \"/home/factory/work/mb/factory/train/train_text_to_image_lora_sdxl.py\", line 563, in main\n",
      "    tokenizer_two = AutoTokenizer.from_pretrained(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 794, in from_pretrained\n",
      "    config = AutoConfig.from_pretrained(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1138, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 631, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 686, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/transformers/utils/hub.py\", line 452, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: segmind/tiny-sd does not appear to have a file named tokenizer_2/config.json. Checkout 'https://huggingface.co/segmind/tiny-sd/main' for available files.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1075, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 681, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/bin/python', 'train_text_to_image_lora_sdxl.py', '--pretrained_model_name_or_path=segmind/tiny-sd', '--pretrained_vae_model_name_or_path=segmind/tiny-sd', '--dataset_name=philipp-zettl/jon_juarez', '--caption_column=text', '--resolution=1024', '--random_flip', '--train_batch_size=1', '--num_train_epochs=2', '--checkpointing_steps=500', '--learning_rate=1e-04', '--lr_scheduler=constant', '--lr_warmup_steps=0']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_text_to_image_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=\"segmind/tiny-sd\" \\\n",
    "  --pretrained_vae_model_name_or_path=\"segmind/tiny-sd\" \\\n",
    "  --dataset_name='philipp-zettl/jon_juarez' --caption_column=\"text\" \\\n",
    "  --resolution=1024 --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --num_train_epochs=2 --checkpointing_steps=500 \\\n",
    "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
    "  #--mixed_precision=\"fp16\" \\\n",
    "  --seed=42 \\\n",
    "  --output_dir=\"tiny-sd-jon_juarez-lora\" \\\n",
    "  --validation_prompt=\"cute dragon creature\" --report_to=\"wandb\" \\\n",
    "  --push_to_hub \\\n",
    "  --hub_model_id \"philipp-zettl/sd-jon_juarez-model-lora-ssd\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "04/07/2024 16:42:18 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'rescale_betas_zero_snr', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "vae/config.json: 100%|█████████████████████████| 602/602 [00:00<00:00, 2.16MB/s]\n",
      "vae/diffusion_pytorch_model.safetensors: 100%|█| 335M/335M [00:30<00:00, 10.9MB/\n",
      "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/work/mb/factory/train/train_dreambooth_lora.py\", line 1429, in <module>\n",
      "    main(args)\n",
      "  File \"/home/factory/work/mb/factory/train/train_dreambooth_lora.py\", line 893, in main\n",
      "    vae.to(accelerator.device, dtype=weight_dtype)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1152, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 825, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1150, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 5.78 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 5.33 GiB memory in use. Of the allocated memory 5.14 GiB is allocated by PyTorch, and 117.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1075, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 681, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/home/factory/.cache/pypoetry/virtualenvs/factory-HxwD1Xz5-py3.11/bin/python', 'train_dreambooth_lora.py', '--pretrained_model_name_or_path=segmind/SSD-1B', '--instance_data_dir=./datasets/margot_robbie', '--output_dir=./models/ssd-margot_robbie-full-lora', '--instance_prompt=MAGROB style', '--class_data_dir=./datasets/image_data', '--class_prompt=style', '--with_prior_preservation', '--num_class_images=10', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--checkpointing_steps=100', '--learning_rate=5e-4', '--report_to=wandb', '--lr_scheduler=polynomial', '--lr_warmup_steps=0', '--max_train_steps=500', '--validation_prompt=MAGROB style woman on a field of flowers', '--validation_epochs=5', '--seed=0', '--push_to_hub', '--hub_model_id', 'philipp-zettl/ssd-margot_robbie-lora']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path='segmind/SSD-1B'  \\\n",
    "  --instance_data_dir='./datasets/margot_robbie' \\\n",
    "  --output_dir='./models/ssd-margot_robbie-full-lora' \\\n",
    "  --instance_prompt=\"MAGROB style\" \\\n",
    "  --class_data_dir='./datasets/image_data' \\\n",
    "  --class_prompt='style' \\\n",
    "  --with_prior_preservation \\\n",
    "  --num_class_images=10 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --checkpointing_steps=100 \\\n",
    "  --learning_rate=5e-4 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --lr_scheduler=\"polynomial\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=500 \\\n",
    "  --validation_prompt=\"MAGROB style woman on a field of flowers\" \\\n",
    "  --validation_epochs=5 \\\n",
    "  --seed=\"0\" \\\n",
    "  --push_to_hub \\\n",
    "  --hub_model_id \"philipp-zettl/ssd-margot_robbie-lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp diffusers/examples/text_to_image/train_text_to_image_lora.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/factory/.cache/huggingface/accelerate/default_config.yaml')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/07/2024 17:31:55 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "{'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "{'resnet_out_scale_factor', 'cross_attention_norm', 'addition_embed_type', 'num_class_embeds', 'attention_type', 'addition_embed_type_num_heads', 'use_linear_projection', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'addition_time_embed_dim', 'resnet_time_scale_shift', 'time_embedding_dim', 'conv_out_kernel', 'mid_block_scale_factor', 'dual_cross_attention', 'time_cond_proj_dim', 'upcast_attention', 'only_cross_attention', 'transformer_layers_per_block', 'class_embed_type', 'time_embedding_type', 'conv_in_kernel', 'mid_block_only_cross_attention', 'num_attention_heads', 'reverse_transformer_layers_per_block', 'time_embedding_act_fn', 'dropout', 'timestep_post_act', 'resnet_skip_time_act', 'class_embeddings_concat', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.\n",
      "Downloading readme: 100%|██████████████████████| 316/316 [00:00<00:00, 1.55MB/s]\n",
      "Downloading data: 100%|██████████████████████| 455M/455M [00:42<00:00, 10.8MB/s]\n",
      "Generating train split: 100%|█████████| 438/438 [00:00<00:00, 468.18 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphilipp-zettl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/factory/work/mb/factory/train/wandb/run-20240407_173248-v51n7dta\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-lake-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/philipp-zettl/text2image-fine-tune\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/philipp-zettl/text2image-fine-tune/runs/v51n7dta\u001b[0m\n",
      "04/07/2024 17:32:49 - INFO - __main__ - ***** Running training *****\n",
      "04/07/2024 17:32:49 - INFO - __main__ -   Num examples = 438\n",
      "04/07/2024 17:32:49 - INFO - __main__ -   Num Epochs = 137\n",
      "04/07/2024 17:32:49 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "04/07/2024 17:32:49 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "04/07/2024 17:32:49 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "04/07/2024 17:32:49 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   1%| | 110/15000 [04:18<8:31:34,  2.06s/it, lr=0.0001, step_loss=0.0030104/07/2024 17:37:08 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:00,  4.21it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  8.06it/s]\u001b[A\n",
      "Steps:   1%| | 220/15000 [08:54<8:13:29,  2.00s/it, lr=9.99e-5, step_loss=0.024304/07/2024 17:41:43 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.64it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.52it/s]\u001b[A\n",
      "Steps:   2%| | 330/15000 [13:25<8:12:59,  2.02s/it, lr=9.99e-5, step_loss=0.003804/07/2024 17:46:15 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.46it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.44it/s]\u001b[A\n",
      "Steps:   3%| | 440/15000 [18:15<9:44:35,  2.41s/it, lr=9.98e-5, step_loss=0.193]04/07/2024 17:51:05 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:00,  4.31it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.97it/s]\u001b[A\n",
      "Steps:   3%| | 500/15000 [21:21<11:14:03,  2.79s/it, lr=9.97e-5, step_loss=0.00904/07/2024 17:54:10 - INFO - accelerate.accelerator - Saving current state to ./finetune/lora/nsfw/checkpoint-500\n",
      "04/07/2024 17:54:12 - INFO - accelerate.checkpointing - Model weights saved in finetune/lora/nsfw/checkpoint-500/model.safetensors\n",
      "04/07/2024 17:54:12 - INFO - accelerate.checkpointing - Optimizer state saved in finetune/lora/nsfw/checkpoint-500/optimizer.bin\n",
      "04/07/2024 17:54:12 - INFO - accelerate.checkpointing - Scheduler state saved in finetune/lora/nsfw/checkpoint-500/scheduler.bin\n",
      "04/07/2024 17:54:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetune/lora/nsfw/checkpoint-500/sampler.bin\n",
      "04/07/2024 17:54:12 - INFO - accelerate.checkpointing - Random states saved in finetune/lora/nsfw/checkpoint-500/random_states_0.pkl\n",
      "Model weights saved in finetune/lora/nsfw/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "04/07/2024 17:54:12 - INFO - __main__ - Saved state to ./finetune/lora/nsfw/checkpoint-500\n",
      "Steps:   4%| | 550/15000 [23:41<9:39:22,  2.41s/it, lr=9.97e-5, step_loss=0.022204/07/2024 17:56:30 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:00,  5.42it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  8.71it/s]\u001b[A\n",
      "Steps:   4%| | 660/15000 [29:04<9:31:30,  2.39s/it, lr=9.95e-5, step_loss=0.003904/07/2024 18:01:54 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:00,  4.10it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  8.12it/s]\u001b[A\n",
      "Steps:   5%|  | 770/15000 [34:28<9:34:52,  2.42s/it, lr=9.94e-5, step_loss=0.26]04/07/2024 18:07:18 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.57it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.51it/s]\u001b[A\n",
      "Steps:   6%| | 880/15000 [39:52<9:25:27,  2.40s/it, lr=9.92e-5, step_loss=0.094304/07/2024 18:12:41 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.53it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.49it/s]\u001b[A\n",
      "Steps:   7%| | 990/15000 [44:43<7:49:20,  2.01s/it, lr=9.89e-5, step_loss=0.015104/07/2024 18:17:33 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.60it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.58it/s]\u001b[A\n",
      "Steps:   7%| | 1000/15000 [45:21<9:46:27,  2.51s/it, lr=9.89e-5, step_loss=0.04104/07/2024 18:18:11 - INFO - accelerate.accelerator - Saving current state to ./finetune/lora/nsfw/checkpoint-1000\n",
      "04/07/2024 18:18:13 - INFO - accelerate.checkpointing - Model weights saved in finetune/lora/nsfw/checkpoint-1000/model.safetensors\n",
      "04/07/2024 18:18:13 - INFO - accelerate.checkpointing - Optimizer state saved in finetune/lora/nsfw/checkpoint-1000/optimizer.bin\n",
      "04/07/2024 18:18:13 - INFO - accelerate.checkpointing - Scheduler state saved in finetune/lora/nsfw/checkpoint-1000/scheduler.bin\n",
      "04/07/2024 18:18:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetune/lora/nsfw/checkpoint-1000/sampler.bin\n",
      "04/07/2024 18:18:13 - INFO - accelerate.checkpointing - Random states saved in finetune/lora/nsfw/checkpoint-1000/random_states_0.pkl\n",
      "Model weights saved in finetune/lora/nsfw/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "04/07/2024 18:18:13 - INFO - __main__ - Saved state to ./finetune/lora/nsfw/checkpoint-1000\n",
      "Steps:   7%| | 1100/15000 [49:16<7:45:14,  2.01s/it, lr=9.87e-5, step_loss=0.04604/07/2024 18:22:06 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  2.82it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  6.70it/s]\u001b[A\n",
      "Steps:   8%| | 1210/15000 [53:47<7:46:03,  2.03s/it, lr=9.84e-5, step_loss=0.20604/07/2024 18:26:37 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  2.83it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  6.79it/s]\u001b[A\n",
      "Steps:   9%| | 1320/15000 [58:49<9:08:22,  2.41s/it, lr=9.81e-5, step_loss=0.35804/07/2024 18:31:39 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  2.76it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  6.62it/s]\u001b[A\n",
      "Steps:  10%| | 1430/15000 [1:04:13<9:05:21,  2.41s/it, lr=9.78e-5, step_loss=0.004/07/2024 18:37:02 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  2.83it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  6.81it/s]\u001b[A\n",
      "Steps:  10%| | 1500/15000 [1:07:45<10:25:20,  2.78s/it, lr=9.76e-5, step_loss=0.04/07/2024 18:40:35 - INFO - accelerate.accelerator - Saving current state to ./finetune/lora/nsfw/checkpoint-1500\n",
      "04/07/2024 18:40:37 - INFO - accelerate.checkpointing - Model weights saved in finetune/lora/nsfw/checkpoint-1500/model.safetensors\n",
      "04/07/2024 18:40:37 - INFO - accelerate.checkpointing - Optimizer state saved in finetune/lora/nsfw/checkpoint-1500/optimizer.bin\n",
      "04/07/2024 18:40:37 - INFO - accelerate.checkpointing - Scheduler state saved in finetune/lora/nsfw/checkpoint-1500/scheduler.bin\n",
      "04/07/2024 18:40:37 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetune/lora/nsfw/checkpoint-1500/sampler.bin\n",
      "04/07/2024 18:40:37 - INFO - accelerate.checkpointing - Random states saved in finetune/lora/nsfw/checkpoint-1500/random_states_0.pkl\n",
      "Model weights saved in finetune/lora/nsfw/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "04/07/2024 18:40:37 - INFO - __main__ - Saved state to ./finetune/lora/nsfw/checkpoint-1500\n",
      "Steps:  10%| | 1540/15000 [1:09:37<8:59:34,  2.41s/it, lr=9.74e-5, step_loss=0.204/07/2024 18:42:27 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  2.89it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  6.86it/s]\u001b[A\n",
      "Steps:  11%| | 1650/15000 [1:15:01<8:55:30,  2.41s/it, lr=9.7e-5, step_loss=0.0204/07/2024 18:47:51 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  2.87it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  6.72it/s]\u001b[A\n",
      "Steps:  12%| | 1760/15000 [1:20:24<8:49:17,  2.40s/it, lr=9.66e-5, step_loss=0.004/07/2024 18:53:14 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:00,  4.34it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  8.01it/s]\u001b[A\n",
      "Steps:  12%| | 1870/15000 [1:25:47<8:46:30,  2.41s/it, lr=9.62e-5, step_loss=0.204/07/2024 18:58:37 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.80it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.63it/s]\u001b[A\n",
      "Steps:  13%|▏| 1980/15000 [1:31:00<7:20:36,  2.03s/it, lr=9.58e-5, step_loss=0.004/07/2024 19:03:50 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: SUPER_PROMPT a nude woman on the beach.\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:00<00:01,  3.26it/s]\u001b[A{'euler_at_final', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_lu_lambdas'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of segmind/tiny-sd.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/tiny-sd.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of segmind/tiny-sd.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:00<00:00,  7.23it/s]\u001b[A\n",
      "Steps:  13%|▏| 1986/15000 [1:31:29<11:03:28,  3.06s/it, lr=9.57e-5, step_loss=0."
     ]
    }
   ],
   "source": [
    "!accelerate launch train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"segmind/tiny-sd\" \\\n",
    "  --dataset_name=\"philipp-zettl/nsfw-images\" \\\n",
    "  --dataloader_num_workers=1 \\\n",
    "  --resolution=512 \\\n",
    "  --center_crop \\\n",
    "  --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-04 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --output_dir=\"./finetune/lora/nsfw\" \\\n",
    "  --push_to_hub \\\n",
    "  --hub_model_id=\"philipp-zettl/tiny-sd-nsfw-lora\" \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"SUPER_PROMPT a nude woman on the beach\" \\\n",
    "  --seed=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
